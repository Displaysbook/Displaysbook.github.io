<!DOCTYPE html>
<html>
<head>
    <title>Audio Visualization Example</title>
    <style>
        canvas {
            border: 1px solid black;
            display: block;
            margin: 0 auto;
        }
    </style>
</head>
<body>
    <h1>Audio Visualization Example</h1>
    <video id="video" width="640" height="480" autoplay></video>
    <button id="start">Start Capture</button>
    <button id="stop">Stop Capture</button>
    <canvas id="canvas" width="640" height="100"></canvas>

    <script>
        const video = document.getElementById('video');
        const startButton = document.getElementById('start');
        const stopButton = document.getElementById('stop');
        const canvas = document.getElementById('canvas');
        const canvasContext = canvas.getContext('2d');
        let mediaStream = null;
        let audioContext = null;
        let analyser = null;
        let source = null;

        startButton.addEventListener('click', async () => {
            try {
                mediaStream = await navigator.mediaDevices.getDisplayMedia({
                    video: true,
                    audio: true
                });
                video.srcObject = mediaStream;

                // Initialize audio context and analyser
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                source = audioContext.createMediaStreamSource(mediaStream);
                analyser = audioContext.createAnalyser();
                source.connect(analyser);
                analyser.fftSize = 2048;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                // Function to draw the waveform
                function draw() {
                    requestAnimationFrame(draw);
                    analyser.getByteTimeDomainData(dataArray);

                    canvasContext.fillStyle = 'rgb(200, 200, 200)';
                    canvasContext.fillRect(0, 0, canvas.width, canvas.height);

                    canvasContext.lineWidth = 2;
                    canvasContext.strokeStyle = 'rgb(0, 0, 0)';
                    canvasContext.beginPath();

                    const sliceWidth = canvas.width * 1.0 / bufferLength;
                    let x = 0;

                    for (let i = 0; i < bufferLength; i++) {
                        const v = dataArray[i] / 128.0; // normalize value
                        const y = v * canvas.height / 2;
                        if (i === 0) {
                            canvasContext.moveTo(x, y);
                        } else {
                            canvasContext.lineTo(x, y);
                        }
                        x += sliceWidth;
                    }

                    canvasContext.lineTo(canvas.width, canvas.height / 2);
                    canvasContext.stroke();
                }

                draw();

            } catch (err) {
                console.error('Error: ' + err);
            }
        });

        stopButton.addEventListener('click', () => {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                video.srcObject = null;
                if (audioContext) {
                    audioContext.close();
                }
                mediaStream = null;
            }
        });
    </script>
</body>
</html>
