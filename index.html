<!DOCTYPE html>
<html>
<head>
    <title>Desktop Capture with Audio Visualization</title>
    <style>
        #canvas {
            border: 1px solid black;
        }
    </style>
</head>
<body>
    <h1>Desktop Capture with Audio Visualization</h1>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas" width="640" height="100"></canvas>
    <button id="start">Start Capture</button>
    <button id="stop">Stop Capture</button>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const startButton = document.getElementById('start');
        const stopButton = document.getElementById('stop');
        let mediaStream = null;
        let audioContext = null;
        let analyser = null;
        let bufferLength = null;
        let dataArray = null;

        startButton.addEventListener('click', async () => {
            try {
                mediaStream = await navigator.mediaDevices.getDisplayMedia({
                    video: true,
                    audio: true
                });
                video.srcObject = mediaStream;

                // Initialize Web Audio API
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(mediaStream);
                analyser = audioContext.createAnalyser();
                source.connect(analyser);

                bufferLength = analyser.frequencyBinCount;
                dataArray = new Uint8Array(bufferLength);

                // Start visualization
                draw();
            } catch (err) {
                console.error('Error: ' + err);
            }
        });

        stopButton.addEventListener('click', () => {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                video.srcObject = null;
                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }
                analyser = null;
                dataArray = null;
            }
        });

        function draw() {
            if (!analyser) return;

            analyser.getByteFrequencyData(dataArray);

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            const barWidth = (canvas.width / bufferLength) * 2.5;
            let barHeight;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
                barHeight = dataArray[i];
                ctx.fillStyle = 'rgb(' + (barHeight + 100) + ',50,50)';
                ctx.fillRect(x, canvas.height - barHeight / 2, barWidth, barHeight / 2);
                x += barWidth + 1;
            }

            requestAnimationFrame(draw);
        }
    </script>
</body>
</html>
